{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "464d2188",
   "metadata": {},
   "source": [
    "# LLM Integration Description\n",
    "LLM Integration refers to incorporation LLMs, in this case, Gemini, into businesses processes for enhanced efficiency, allowing for applications to leverage advanced NLP capabilites for a wide range of tasks.\n",
    "\n",
    "Some key concepts include...\n",
    "* API CAlls\n",
    "* Prompt Engineering\n",
    "* Data Handeling\n",
    "* RAG\n",
    "\n",
    "In this portion of the project, we are aiming to conduct LLM integration through: \n",
    "* Lead Scoring - identify and prioritize high value leads\n",
    "* Account Health - detects churn risks or upsell opportunities\n",
    "* Semantic Search - make chatbot retrieve and respond intelligently to business or sales data\n",
    "\n",
    "### Gemini: What is it?\n",
    "Gemini is an LLM developed by Google that allows for reasoning, code generation, and instruction following. \n",
    "\n",
    "### API - Application Programming Interface\n",
    "API will help us bridge between the LLM and the sent request. The API Key is a password that identifies the project when you use an APi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9261bdb7",
   "metadata": {},
   "source": [
    "## Step 1: Install Packages and Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf8b2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: python-dotenv in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.2.1)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.28.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.187.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-generativeai) (2.43.0)\n",
      "Requirement already satisfied: protobuf in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-generativeai) (6.33.1)\n",
      "Requirement already satisfied: pydantic in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-generativeai) (2.7.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-generativeai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-generativeai) (4.15.0)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.76.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (6.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.75.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2022.12.7)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.31.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic->google-generativeai) (2.18.2)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.28.1-py3-none-any.whl (173 kB)\n",
      "Downloading grpcio_status-1.71.2-py3-none-any.whl (14 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading protobuf-5.29.5-cp38-abi3-macosx_10_9_universal2.whl (418 kB)\n",
      "Downloading google_api_python_client-2.187.0-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading google_auth_httplib2-0.2.1-py3-none-any.whl (9.5 kB)\n",
      "Downloading httplib2-0.31.0-py3-none-any.whl (91 kB)\n",
      "Downloading uritemplate-4.2.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: uritemplate, protobuf, httplib2, proto-plus, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "\u001b[2K  Attempting uninstall: protobuf\n",
      "\u001b[2K    Found existing installation: protobuf 6.33.1\n",
      "\u001b[2K    Uninstalling protobuf-6.33.1:\n",
      "\u001b[2K      Successfully uninstalled protobuf-6.33.1\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [google-generativeai]ogle-ai-generativelanguage]\n",
      "\u001b[1A\u001b[2KSuccessfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.28.1 google-api-python-client-2.187.0 google-auth-httplib2-0.2.1 google-generativeai-0.8.5 grpcio-status-1.71.2 httplib2-0.31.0 proto-plus-1.26.1 protobuf-5.29.5 uritemplate-4.2.0\n"
     ]
    }
   ],
   "source": [
    "#install Gemini\n",
    "!pip install google-generativeai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc3b1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to Gemini API\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables .env\n",
    "load_dotenv()\n",
    "\n",
    "# Get the Gemini API key from .env\n",
    "api_key = os.getenv('GEMINI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69ed107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.10) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "DefaultCredentialsError",
     "evalue": "\n  No API_KEY or ADC found. Please either:\n    - Set the `GOOGLE_API_KEY` environment variable.\n    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\n    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m genai\u001b[38;5;241m.\u001b[39mconfigure(api_key\u001b[38;5;241m=\u001b[39mapi_key)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Debug: Print available models\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable models:\u001b[39m\u001b[38;5;124m\"\u001b[39m, [m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m genai\u001b[38;5;241m.\u001b[39mlist_models()])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Create the model with correct name\u001b[39;00m\n\u001b[1;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/gemini-pro-latest\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Update model name to match available models\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 16\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m genai\u001b[38;5;241m.\u001b[39mconfigure(api_key\u001b[38;5;241m=\u001b[39mapi_key)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Debug: Print available models\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable models:\u001b[39m\u001b[38;5;124m\"\u001b[39m, [m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m genai\u001b[38;5;241m.\u001b[39mlist_models()])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Create the model with correct name\u001b[39;00m\n\u001b[1;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/gemini-pro-latest\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Update model name to match available models\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/generativeai/models.py:202\u001b[0m, in \u001b[0;36mlist_models\u001b[0;34m(page_size, client, request_options)\u001b[0m\n\u001b[1;32m    199\u001b[0m     request_options \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[43mget_default_model_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m client\u001b[38;5;241m.\u001b[39mlist_models(page_size\u001b[38;5;241m=\u001b[39mpage_size, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options):\n\u001b[1;32m    205\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;241m.\u001b[39mto_dict(model)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/generativeai/client.py:372\u001b[0m, in \u001b[0;36mget_default_model_client\u001b[0;34m()\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_default_model_client\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m glm\u001b[38;5;241m.\u001b[39mModelServiceAsyncClient:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_client_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_client\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/generativeai/client.py:289\u001b[0m, in \u001b[0;36m_ClientManager.get_default_client\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    287\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclients\u001b[38;5;241m.\u001b[39mget(name)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 289\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclients[name] \u001b[38;5;241m=\u001b[39m client\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m client\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/generativeai/client.py:249\u001b[0m, in \u001b[0;36m_ClientManager.make_client\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ga_exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    243\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  No API_KEY or ADC found. Please either:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    - Set the `GOOGLE_API_KEY` environment variable.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    248\u001b[0m     )\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata:\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m client\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/generativeai/client.py:241\u001b[0m, in \u001b[0;36m_ClientManager.make_client\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m patch_colab_gce_credentials():\n\u001b[0;32m--> 241\u001b[0m         client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ga_exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    243\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  No API_KEY or ADC found. Please either:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    - Set the `GOOGLE_API_KEY` environment variable.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    248\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/model_service/client.py:661\u001b[0m, in \u001b[0;36mModelServiceClient.__init__\u001b[0;34m(self, credentials, transport, client_options, client_info)\u001b[0m\n\u001b[1;32m    653\u001b[0m     transport_init: Union[\n\u001b[1;32m    654\u001b[0m         Type[ModelServiceTransport], Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, ModelServiceTransport]\n\u001b[1;32m    655\u001b[0m     ] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m cast(Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, ModelServiceTransport], transport)\n\u001b[1;32m    659\u001b[0m     )\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;66;03m# initialize with the provided callable or the passed in class\u001b[39;00m\n\u001b[0;32m--> 661\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport \u001b[38;5;241m=\u001b[39m \u001b[43mtransport_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_cert_source_for_mtls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_cert_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport):\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m CLIENT_LOGGING_SUPPORTED \u001b[38;5;129;01mand\u001b[39;00m _LOGGER\u001b[38;5;241m.\u001b[39misEnabledFor(\n\u001b[1;32m    675\u001b[0m         std_logging\u001b[38;5;241m.\u001b[39mDEBUG\n\u001b[1;32m    676\u001b[0m     ):  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/model_service/transports/grpc.py:239\u001b[0m, in \u001b[0;36mModelServiceGrpcTransport.__init__\u001b[0;34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl_channel_credentials \u001b[38;5;241m=\u001b[39m grpc\u001b[38;5;241m.\u001b[39mssl_channel_credentials(\n\u001b[1;32m    235\u001b[0m                 certificate_chain\u001b[38;5;241m=\u001b[39mcert, private_key\u001b[38;5;241m=\u001b[39mkey\n\u001b[1;32m    236\u001b[0m             )\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grpc_channel:\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# initialize with the provided callable or the default channel\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     channel_init \u001b[38;5;241m=\u001b[39m channel \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreate_channel\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/model_service/transports/base.py:103\u001b[0m, in \u001b[0;36mModelServiceTransport.__init__\u001b[0;34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mload_credentials_from_file(\n\u001b[1;32m    100\u001b[0m         credentials_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscopes_kwargs, quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id\n\u001b[1;32m    101\u001b[0m     )\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_credentials:\n\u001b[0;32m--> 103\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m \u001b[43mgoogle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mscopes_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_gdch_audience\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/auth/_default.py:739\u001b[0m, in \u001b[0;36mdefault\u001b[0;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[1;32m    731\u001b[0m             _LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    732\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo project ID could be determined. Consider running \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    733\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    734\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    735\u001b[0m                 environment_vars\u001b[38;5;241m.\u001b[39mPROJECT,\n\u001b[1;32m    736\u001b[0m             )\n\u001b[1;32m    737\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[0;32m--> 739\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m: \n  No API_KEY or ADC found. Please either:\n    - Set the `GOOGLE_API_KEY` environment variable.\n    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\n    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information."
     ]
    }
   ],
   "source": [
    "#initialize Gemini and import necessary libraries\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Dict, Any, List, Optional\n",
    "\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import joblib\n",
    "\n",
    "# Configure Gemini with your API key\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Debug: Print available models\n",
    "print(\"Available models:\", [m.name for m in genai.list_models()])\n",
    "\n",
    "# Create the model with correct name\n",
    "model = genai.GenerativeModel('models/gemini-pro-latest')  # Update model name to match available models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd468b3e",
   "metadata": {},
   "source": [
    "## Step 2: Create Helper Funcitons for Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c32f367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBDTLeadScorer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        pipeline=None,\n",
    "        features: Optional[List[str]] = None,\n",
    "        model_path: Optional[str] = None,\n",
    "        feature_path: Optional[str] = None,\n",
    "    ):\n",
    "        if pipeline is not None:\n",
    "            self.pipeline = pipeline\n",
    "        elif model_path and os.path.exists(model_path):\n",
    "            self.pipeline = joblib.load(model_path)\n",
    "        else:\n",
    "            raise ValueError(\"Provide a fitted pipeline or a valid model_path.\")\n",
    "\n",
    "        # Prefer explicit features arg; else try load from file; else None\n",
    "        if features is not None:\n",
    "            self.features = features\n",
    "        elif feature_path and os.path.exists(feature_path):\n",
    "            self.features = joblib.load(feature_path)\n",
    "        else:\n",
    "            self.features = None  # pipeline must handle missing order\n",
    "\n",
    "    def predict(self, features: Dict[str, Any]) -> float:\n",
    "        X = pd.DataFrame([features])\n",
    "        if self.features:\n",
    "            X = X.reindex(columns=self.features)\n",
    "        proba = self.pipeline.predict_proba(X)[:, 1]\n",
    "        return float(proba[0])\n",
    "\n",
    "\n",
    "class AccountHealthScorer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        pipeline=None,\n",
    "        features: Optional[List[str]] = None,\n",
    "        model_path: Optional[str] = None,\n",
    "        feature_path: Optional[str] = None,\n",
    "    ):\n",
    "        if pipeline is not None:\n",
    "            self.pipeline = pipeline\n",
    "        elif model_path and os.path.exists(model_path):\n",
    "            self.pipeline = joblib.load(model_path)\n",
    "        else:\n",
    "            raise ValueError(\"Provide a fitted pipeline or a valid model_path.\")\n",
    "\n",
    "        if features is not None:\n",
    "            self.features = features\n",
    "        elif feature_path and os.path.exists(feature_path):\n",
    "            self.features = joblib.load(feature_path)\n",
    "        else:\n",
    "            self.features = None\n",
    "\n",
    "    def predict(self, features: Dict[str, Any]) -> float:\n",
    "        X = pd.DataFrame([features])\n",
    "        if self.features:\n",
    "            X = X.reindex(columns=self.features)\n",
    "        proba = self.pipeline.predict_proba(X)[:, 1]  # adjust if needed\n",
    "        return float(proba[0])\n",
    "\n",
    "\n",
    "class SemanticSearcher:\n",
    "    \"\"\"Use an existing Chroma collection/client if you already created one.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        collection=None,\n",
    "        client=None,\n",
    "        persist_dir: Optional[str] = None,\n",
    "        collection_name: str = \"crm_docs\",\n",
    "    ):\n",
    "        if collection is not None:\n",
    "            self.collection = collection\n",
    "        else:\n",
    "            if client is None:\n",
    "                if not persist_dir:\n",
    "                    raise ValueError(\"Provide collection/client OR persist_dir.\")\n",
    "                import chromadb\n",
    "                client = chromadb.PersistentClient(path=persist_dir)\n",
    "            self.collection = client.get_or_create_collection(collection_name)\n",
    "\n",
    "    def search(self, query: str, n_results: int = 5, where: Optional[Dict[str, Any]] = None):\n",
    "        res = self.collection.query(query_texts=[query], n_results=n_results, where=where)\n",
    "        docs = res.get(\"documents\", [[]])[0]\n",
    "        metas = res.get(\"metadatas\", [[]])[0]\n",
    "        dists = res.get(\"distances\", [[]])[0] if \"distances\" in res else [None]*len(docs)\n",
    "        out = []\n",
    "        for i, txt in enumerate(docs):\n",
    "            meta = metas[i] if i < len(metas) else {}\n",
    "            out.append({\n",
    "                \"text\": txt,\n",
    "                \"source\": (meta or {}).get(\"source\", f\"doc_{i}\"),\n",
    "                \"score\": dists[i]\n",
    "            })\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f560755f",
   "metadata": {},
   "source": [
    "## Step 3: Create Main Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f639ec6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "GEMINI_API_KEY not set in your .env",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGEMINI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m api_key:\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGEMINI_API_KEY not set in your .env\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m genai\u001b[38;5;241m.\u001b[39mconfigure(api_key\u001b[38;5;241m=\u001b[39mapi_key)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCRMAssistant\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: GEMINI_API_KEY not set in your .env"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"GEMINI_API_KEY not set in your .env\")\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "class CRMAssistant:\n",
    "    def __init__(self, lead_scorer, health_scorer, semantic_searcher, model_name=\"gemini-pro\"):\n",
    "        self.lead_scorer = lead_scorer\n",
    "        self.health_scorer = health_scorer\n",
    "        self.semantic_searcher = semantic_searcher\n",
    "        self.model = genai.GenerativeModel(model_name)\n",
    "\n",
    "    @staticmethod\n",
    "    def _fmt(docs: List[Dict[str, Any]]) -> str:\n",
    "        return \"\\n\".join(f\"[{d.get('source','doc')}] {d.get('text','')}\" for d in docs)\n",
    "\n",
    "    def process_lead_score(self, lead_score: float, lead_data: Dict[str, Any]) -> str:\n",
    "        prompt = f\"\"\"\n",
    "You are a CRM assistant. Given a lead score of {lead_score:.2f} and this lead data:\n",
    "{lead_data}\n",
    "\n",
    "Provide:\n",
    "- 2–4 next actions,\n",
    "- a short rationale referencing top drivers,\n",
    "- a one-line priority (High/Med/Low).\n",
    "\"\"\"\n",
    "        return self.model.generate_content(prompt).text\n",
    "\n",
    "    def analyze_account_health(self, health_score: float, account_data: Dict[str, Any]) -> str:\n",
    "        prompt = f\"\"\"\n",
    "You are a CRM assistant. Account health score: {health_score:.2f}.\n",
    "Account data:\n",
    "{account_data}\n",
    "\n",
    "Return:\n",
    "- 3 targeted recommendations,\n",
    "- key risks,\n",
    "- owner + due date for the first action.\n",
    "\"\"\"\n",
    "        return self.model.generate_content(prompt).text\n",
    "\n",
    "    def semantic_search_response(self, query: str, context_docs: List[Dict[str, Any]]) -> str:\n",
    "        ctx = self._fmt(context_docs)\n",
    "        prompt = f\"\"\"\n",
    "Use the CRM context to answer. If info is missing, say what is needed.\n",
    "\n",
    "Context:\n",
    "{ctx}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Reply with a brief summary and bullet points. Cite sources in [brackets].\n",
    "\"\"\"\n",
    "        return self.model.generate_content(prompt).text\n",
    "\n",
    "    def process_query(self, query: str, context: Optional[Dict[str, Any]] = None) -> str:\n",
    "        q = query.lower()\n",
    "        if \"lead\" in q and any(k in q for k in [\"score\", \"convert\", \"probability\"]):\n",
    "            if context is None:\n",
    "                return \"I need lead features (or a lead_id I can fetch) to score this lead.\"\n",
    "            score = self.lead_scorer.predict(context)\n",
    "            return self.process_lead_score(score, context)\n",
    "\n",
    "        if any(k in q for k in [\"health\", \"churn\", \"risk\", \"renewal\"]):\n",
    "            if context is None:\n",
    "                return \"I need account features (or an account_id I can fetch) to assess health.\"\n",
    "            score = self.health_scorer.predict(context)\n",
    "            return self.analyze_account_health(score, context)\n",
    "\n",
    "        docs = self.semantic_searcher.search(query)\n",
    "        return self.semantic_search_response(query, docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0759ddb4",
   "metadata": {},
   "source": [
    "## Step 4: Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b03caa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Gemini LLM Integration ===\n",
      "\n",
      "Prompt: What are the key benefits of using LLMs in CRM systems?\n",
      "\n",
      "Response: Of course. The integration of Large Language Models (LLMs) into Customer Relationship Management (CRM) systems is a game-changer, transforming them from passive databases into proactive, intelligent partners.\n",
      "\n",
      "The key benefits can be broken down by business function:\n",
      "\n",
      "---\n",
      "\n",
      "### 1. Enhanced Sales Productivity and Effectiveness\n",
      "\n",
      "Sales teams spend a significant amount of time on administrative tasks rather than selling. LLMs directly address this inefficiency.\n",
      "\n",
      "*   **Automated Communication Drafting:** LLMs can instantly generate personalized outreach emails, follow-ups, and proposals based on customer data in the CRM.\n",
      "    *   **Benefit:** Massively reduces the time reps spend writing, allowing them to engage more leads. It also ensures a consistent and high-quality tone across the team.\n",
      "\n",
      "*   **Intelligent Call & Meeting Summarization:** LLMs can transcribe audio from sales calls, summarize the key points, identify customer sentiment, and extract action items directly into the CRM.\n",
      "    *   **Benefit:** Eliminates manual note-taking, creates perfect records for future reference, and makes coaching and deal reviews far more efficient.\n",
      "\n",
      "*   **\"Deal Gaps\" and Next-Best-Action Suggestions:** By analyzing the entire communication history of a deal (emails, calls, notes), an LLM can identify potential risks, suggest the next logical step (e.g., \"You haven't discussed pricing with the decision-maker yet\"), or recommend relevant content to share.\n",
      "    *   **Benefit:** Acts as a co-pilot for sales reps, improving forecasting accuracy and increasing the probability of closing deals.\n",
      "\n",
      "*   **Lead Prioritization and Scoring:** LLMs can analyze the content of a lead's inquiries and interactions to understand their intent and urgency, providing a more nuanced lead score than traditional metric-based systems.\n",
      "    *   **Benefit:** Helps sales teams focus their energy on the most promising leads, improving conversion rates.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. Revolutionized Customer Service and Support\n",
      "\n",
      "LLMs empower support teams to provide faster, more accurate, and more empathetic service.\n",
      "\n",
      "*   **Smarter Chatbots and Virtual Agents:** LLM-powered chatbots can understand complex, multi-turn conversations and provide nuanced answers by drawing from a knowledge base. They can handle a much wider range of queries than traditional, rule-based bots.\n",
      "    *   **Benefit:** Provides 24/7 instant support, resolves a higher percentage of issues without human intervention, and dramatically reduces operational costs.\n",
      "\n",
      "*   **Agent Assist and Suggested Replies:** When a human agent takes over, the LLM can listen in or read the ticket and provide real-time suggestions, relevant knowledge base articles, and pre-drafted, context-aware replies.\n",
      "    *   **Benefit:** Drastically reduces response times, improves first-contact resolution rates, and helps new agents get up to speed quickly.\n",
      "\n",
      "*   **Automated Ticket Summarization and Routing:** LLMs can read an incoming support ticket, understand its intent, sentiment, and urgency, summarize it for the agent, and automatically route it to the correct department (e.g., Billing, Technical Support).\n",
      "    *   **Benefit:** Ensures tickets get to the right person faster, leading to quicker resolutions and a better customer experience.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. Supercharged Marketing and Personalization\n",
      "\n",
      "Marketers can use LLMs to create more relevant and effective campaigns at scale.\n",
      "\n",
      "*   **Hyper-Personalized Content Generation:** LLMs can generate marketing copy (emails, social media posts, ad copy) tailored to specific customer segments or even individuals based on their purchase history, support interactions, and browsing behavior stored in the CRM.\n",
      "    *   **Benefit:** Increases engagement, click-through rates, and conversion rates by delivering messages that truly resonate with the audience.\n",
      "\n",
      "*   **Advanced Audience Segmentation:** By analyzing unstructured data like support ticket text and survey responses, LLMs can help identify nuanced customer segments that would be missed by traditional filtering (e.g., \"customers who are happy with the product but frustrated with the delivery process\").\n",
      "    *   **Benefit:** Enables highly targeted and more effective marketing campaigns.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. Streamlined Operations and Data Management\n",
      "\n",
      "The foundation of a good CRM is good data. LLMs help ensure data is clean, complete, and easy to access.\n",
      "\n",
      "*   **Automated Data Entry and Enrichment:** LLMs can automatically extract information from emails (like a new contact in a signature) or web pages and populate or update records in the CRM, eliminating manual data entry.\n",
      "    *   **Benefit:** Saves countless hours of administrative work, reduces human error, and improves overall data hygiene.\n",
      "\n",
      "*   **Natural Language Search and Reporting:** Users can ask the CRM questions in plain English, like \"Show me all deals over $50k in the pipeline for Q4 in the manufacturing sector\" or \"Summarize our top customer complaints from last month.\"\n",
      "    *   **Benefit:** Democratizes data access. Anyone can get complex insights without needing to know how to build a custom report, leading to faster, data-driven decisions.\n",
      "\n",
      "### Summary: The Core Shift\n",
      "\n",
      "The overarching benefit is the transformation of the CRM from a **System of Record** to a **System of Intelligence**.\n",
      "\n",
      "*   **Before LLMs:** A CRM was a place to *store* information. Its value depended on how diligently humans entered and interpreted the data.\n",
      "*   **With LLMs:** The CRM becomes a proactive partner that *understands* the information, *automates* workflows, and *generates insights* to help every employee be more effective in their role. This leads to increased revenue, lower operational costs, and a vastly improved customer experience.\n",
      "\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "# Basic LLM Integration Test\n",
    "# Test function remains the same\n",
    "def test_llm_integration():\n",
    "    prompt = \"What are the key benefits of using LLMs in CRM systems?\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config={\n",
    "                \"temperature\": 0.7,\n",
    "                \"top_p\": 0.8,\n",
    "                \"top_k\": 40\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(\"\\n=== Testing Gemini LLM Integration ===\")\n",
    "        print(\"\\nPrompt:\", prompt)\n",
    "        print(\"\\nResponse:\", response.text)\n",
    "        print(\"\\n=====================================\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error testing LLM integration: {str(e)}\")\n",
    "        print(\"API Key configured:\", bool(api_key))\n",
    "        print(\"Available models:\", [m.name for m in genai.list_models()])\n",
    "\n",
    "# Run the test\n",
    "test_llm_integration()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
