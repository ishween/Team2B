{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8160cea",
   "metadata": {},
   "source": [
    "# Semantic Search Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25a556a",
   "metadata": {},
   "source": [
    "Semantic search understands the **meaning** behind searches rather than exact word matches. If you search \"car\", it can find \"vehicle\", \"automobile\", \"sedan\" because they're related concepts. This means sales teams can ask natural questions like:\n",
    "- \"Show me technology accounts with high revenue\"\n",
    "- \"Find medical sector companies in the United States\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0896db4",
   "metadata": {},
   "source": [
    "Vector Embeddings: Converting text to numbers\n",
    "- Computers can't understand text, but they understand numbers\n",
    "- Similar meanings = similar numbers\n",
    "\n",
    "ChromaDB: A smart database for these vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecb5f1e",
   "metadata": {},
   "source": [
    "## Step 1: Import Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9267df",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cae3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.9.1-cp310-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (1.1.4)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.14.0)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached regex-2025.11.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.31.0)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.12.7)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Using cached sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Using cached transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\n",
      "Using cached regex-2025.11.3-cp310-cp310-macosx_11_0_arm64.whl (288 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\n",
      "Using cached torch-2.9.1-cp310-none-macosx_11_0_arm64.whl (74.5 MB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, safetensors, regex, networkx, torch, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "\u001b[2K  Attempting uninstall: huggingface-hub[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/10\u001b[0m [torch]kx]\n",
      "\u001b[2K    Found existing installation: huggingface_hub 1.1.4━━━━━━━━\u001b[0m \u001b[32m 5/10\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling huggingface_hub-1.1.4:[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/10\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled huggingface_hub-1.1.4━━━━━━━━━━\u001b[0m \u001b[32m 5/10\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: tokenizers0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/10\u001b[0m [huggingface-hub]\n",
      "\u001b[2K    Found existing installation: tokenizers 0.19.1━━━━━━━━━━━━\u001b[0m \u001b[32m 6/10\u001b[0m [huggingface-hub]\n",
      "\u001b[2K    Uninstalling tokenizers-0.19.1:0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/10\u001b[0m [huggingface-hub]\n",
      "\u001b[2K      Successfully uninstalled tokenizers-0.19.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/10\u001b[0m [huggingface-hub]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [sentence-transformers]ence-transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed huggingface-hub-0.36.0 mpmath-1.3.0 networkx-3.4.2 regex-2025.11.3 safetensors-0.6.2 sentence-transformers-5.1.2 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.1 transformers-4.57.1\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87db7097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-1.3.4-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.2 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from chromadb) (2.7.1)\n",
      "Collecting pybase64>=1.4.1 (from chromadb)\n",
      "  Downloading pybase64-1.4.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from chromadb) (4.11.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.23.2-cp310-cp310-macosx_13_0_arm64.whl.metadata (5.1 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from chromadb) (0.22.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from chromadb) (4.66.4)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from chromadb) (7.7.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.76.0-cp310-cp310-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-5.0.0-cp39-abi3-macosx_10_12_universal2.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from chromadb) (0.20.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tenacity>=8.2.3 (from chromadb)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from chromadb) (6.0.1)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.2.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from chromadb) (3.11.4)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from chromadb) (14.2.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from chromadb) (4.22.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.31.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3.0,>=2.7->posthog<6.0.0,>=2.4.0->chromadb) (2022.12.7)\n",
      "Requirement already satisfied: packaging>=19.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (23.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Collecting typing-extensions>=4.5.0 (from chromadb)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (4.3.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jsonschema>=4.19.0->chromadb) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jsonschema>=4.19.0->chromadb) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jsonschema>=4.19.0->chromadb) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jsonschema>=4.19.0->chromadb) (0.18.1)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Collecting cachetools<7.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading cachetools-6.2.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-6.33.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-8.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting googleapis-common-protos~=1.57 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.38.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pydantic>=1.9->chromadb) (2.18.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.3.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.1.3)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.7.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.5 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.22.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.1.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Downloading chromadb-1.3.4-cp39-abi3-macosx_11_0_arm64.whl (19.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading bcrypt-5.0.0-cp39-abi3-macosx_10_12_universal2.whl (495 kB)\n",
      "Downloading build-1.3.0-py3-none-any.whl (23 kB)\n",
      "Downloading grpcio-1.76.0-cp310-cp310-macosx_11_0_universal2.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\n",
      "Downloading cachetools-6.2.2-py3-none-any.whl (11 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading mmh3-5.2.0-cp310-cp310-macosx_11_0_arm64.whl (40 kB)\n",
      "Downloading onnxruntime-1.23.2-cp310-cp310-macosx_13_0_arm64.whl (17.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.2/17.2 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
      "Downloading importlib_metadata-8.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.38.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
      "Downloading googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "Downloading opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
      "Downloading protobuf-6.33.1-cp39-abi3-macosx_10_9_universal2.whl (427 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading pybase64-1.4.2-cp310-cp310-macosx_11_0_arm64.whl (31 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading httptools-0.7.1-cp310-cp310-macosx_11_0_arm64.whl (109 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading uvloop-0.22.1-cp310-cp310-macosx_10_9_universal2.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.1-cp310-cp310-macosx_11_0_arm64.whl (394 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=e2428e395fed921f9a0a8b5e8f3919ad54d2b8d381375b874369b9186b991481\n",
      "  Stored in directory: /Users/apple/Library/Caches/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, flatbuffers, durationpy, zipp, uvloop, typing-extensions, tenacity, python-dotenv, pyproject_hooks, pybase64, pyasn1, protobuf, oauthlib, mmh3, importlib-resources, humanfriendly, httptools, cachetools, bcrypt, backoff, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, importlib-metadata, grpcio, googleapis-common-protos, coloredlogs, build, watchfiles, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, google-auth, opentelemetry-semantic-conventions, kubernetes, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
      "\u001b[2K  Attempting uninstall: typing-extensions\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.11.0\n",
      "\u001b[2K    Uninstalling typing_extensions-4.11.0:\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.11.0━━━━━━━━━━━\u001b[0m \u001b[32m 5/40\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: tenacity━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/40\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Found existing installation: tenacity 8.2.2━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/40\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Uninstalling tenacity-8.2.2:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/40\u001b[0m [typing-extensions]\n",
      "\u001b[2K      Successfully uninstalled tenacity-8.2.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/40\u001b[0m [typing-extensions]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40/40\u001b[0m [chromadb]chromadb]kubernetes]]y-api]s]\n",
      "\u001b[1A\u001b[2KSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 cachetools-6.2.2 chromadb-1.3.4 coloredlogs-15.0.1 durationpy-0.10 flatbuffers-25.9.23 google-auth-2.43.0 googleapis-common-protos-1.72.0 grpcio-1.76.0 httptools-0.7.1 humanfriendly-10.0 importlib-metadata-8.7.0 importlib-resources-6.5.2 kubernetes-34.1.0 mmh3-5.2.0 oauthlib-3.3.1 onnxruntime-1.23.2 opentelemetry-api-1.38.0 opentelemetry-exporter-otlp-proto-common-1.38.0 opentelemetry-exporter-otlp-proto-grpc-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 posthog-5.4.0 protobuf-6.33.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 pybase64-1.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.2.1 requests-oauthlib-2.0.0 rsa-4.9.1 tenacity-9.1.2 typing-extensions-4.15.0 uvloop-0.22.1 watchfiles-1.1.1 zipp-3.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19937be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730833e9",
   "metadata": {},
   "source": [
    "## Step 2: Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33f07fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.abspath(\"../data_directory/clean_data\")\n",
    "\n",
    "# Read the data\n",
    "pipeline = pd.read_csv(os.path.join(base_path, \"Pipeline.csv\"))\n",
    "accounts = pd.read_csv(os.path.join(base_path, \"Accounts.csv\"))\n",
    "teams = pd.read_csv(os.path.join(base_path, \"Teams.csv\"))\n",
    "products = pd.read_csv(os.path.join(base_path, \"Products.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2515d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 85 accounts, 8800 opportunities\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded: {len(accounts)} accounts, {len(pipeline)} opportunities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884de310",
   "metadata": {},
   "source": [
    "## Step 3: Create Searchable Text Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eae761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This helps the AI understand what each account is about by making it human-readable text\n",
    "def create_account_description(row):\n",
    "    \"\"\"Convert account data into searchable text\"\"\"\n",
    "    description = f\"\"\"\n",
    "    Sector: {row['sector']} - {row['sector']} industry\n",
    "    Account: {row['account']}\n",
    "    This is a {row['sector']} company with:\n",
    "    Revenue: ${row['revenue']} million\n",
    "    Employees: {row['employees']}\n",
    "    Location: {row['office_location']}\n",
    "    Established: {row['year_established']}\n",
    "    \"\"\"\n",
    "    if pd.notna(row['subsidiary_of']):\n",
    "        description += f\"Subsidiary of: {row['subsidiary_of']}\\n\"\n",
    "    return description.strip()\n",
    "\n",
    "def create_opportunity_description(row):\n",
    "    \"\"\"Convert opportunity data into searchable text\"\"\"\n",
    "    description = f\"\"\"\n",
    "    Opportunity ID: {row['opportunity_id']}\n",
    "    Sales Agent: {row['sales_agent']}\n",
    "    Product: {row['product']}\n",
    "    Account: {row['account']}\n",
    "    Deal Stage: {row['deal_stage']}\n",
    "    Close Value: ${row['close_value']}\n",
    "    \"\"\"\n",
    "    if pd.notna(row['engage_date']):\n",
    "        description += f\"Engaged: {row['engage_date']}\\n\"\n",
    "    if pd.notna(row['close_date']):\n",
    "        description += f\"Closed: {row['close_date']}\\n\"\n",
    "    \n",
    "    return description.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c66bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply descriptions to dataframes\n",
    "accounts['search_text'] = accounts.apply(create_account_description, axis=1)\n",
    "pipeline['search_text'] = pipeline.apply(create_opportunity_description, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44071b0",
   "metadata": {},
   "source": [
    "## Step 4: Initialize the Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e69f001f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456dc4ac1879477b81a96f0024097bf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622038927a8e4938afae48b59d0c5555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a925959848fa429c93403d335559a482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ac022b23a44084ac1df40c067c9868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3dd5e7b364c413fba934cb2255a763a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67003fe0ed44d97b2a236724bdc5575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a92f0a459d54fec8313b2b849ca8ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3383b14fba4fcda1e469839c7a3f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b2eb2d8ee14e7f962bd74c0097a324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d815d33e66943bfa2da1824d0962bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f14e2d72134fd68e850af01cd4f4d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# This model converts text into numbers (vectors) that capture meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa192b0e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4741c9f",
   "metadata": {},
   "source": [
    "## Step 5: Set Up ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62459434",
   "metadata": {},
   "source": [
    "Made two separate ChromaDB collections: one for accounts, one for opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02eb9f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB collections created\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    chroma_client = chromadb.Client(Settings(\n",
    "        persist_directory=\"./chroma_db\",\n",
    "        anonymized_telemetry=False\n",
    "    ))\n",
    "    \n",
    "    # Delete old collections if they exist\n",
    "    try:\n",
    "        chroma_client.delete_collection(\"crm_accounts\")\n",
    "        chroma_client.delete_collection(\"crm_opportunities\")\n",
    "    except:\n",
    "        pass  # Collections might not exist yet\n",
    "    \n",
    "    # Create new collections\n",
    "    # Collection 1: Accounts\n",
    "    accounts_collection = chroma_client.create_collection(\n",
    "        name=\"crm_accounts\",\n",
    "        metadata={\"description\": \"CRM account data\"}\n",
    "    )\n",
    "    \n",
    "    # Collection 1: Opportunities\n",
    "    opportunities_collection = chroma_client.create_collection(\n",
    "        name=\"crm_opportunities\",\n",
    "        metadata={\"description\": \"Sales opportunities data\"}\n",
    "    )\n",
    "    \n",
    "    print(\"ChromaDB collections created\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error setting up ChromaDB: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acd33c2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2c6ee8e",
   "metadata": {},
   "source": [
    "## Step 6: Add Accounts to ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd5a88b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 20/85 accounts\n",
      "  Processed 40/85 accounts\n",
      "  Processed 60/85 accounts\n",
      "  Processed 80/85 accounts\n",
      "Added 85 accounts!\n"
     ]
    }
   ],
   "source": [
    "#Adding accounts to vector database\n",
    "for idx, row in accounts.iterrows():\n",
    "    # Get the text description\n",
    "    text = row['search_text']\n",
    "    \n",
    "    # Convert to embedding (vector)\n",
    "    embedding = model.encode(text).tolist()\n",
    "    \n",
    "    # Store in ChromaDB with metadata\n",
    "    accounts_collection.add(\n",
    "        embeddings=[embedding],\n",
    "        documents=[text],\n",
    "        metadatas=[{\n",
    "            'account': str(row['account']),\n",
    "            'sector': str(row['sector']),\n",
    "            'revenue': str(row['revenue']),\n",
    "            'employees': str(row['employees']),\n",
    "            'location': str(row['office_location'])\n",
    "        }],\n",
    "        ids=[f\"account_{idx}\"]\n",
    "    )\n",
    "    \n",
    "    if (idx + 1) % 20 == 0:\n",
    "        print(f\"  Processed {idx + 1}/{len(accounts)} accounts\")\n",
    "\n",
    "print(f\"Added {len(accounts)} accounts!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480891b2",
   "metadata": {},
   "source": [
    "## Step 7: Add Opportunities to ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1499cd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 500/8800 opportunities\n",
      "  Processed 1000/8800 opportunities\n",
      "  Processed 1500/8800 opportunities\n",
      "  Processed 2000/8800 opportunities\n",
      "  Processed 2500/8800 opportunities\n",
      "  Processed 3000/8800 opportunities\n",
      "  Processed 3500/8800 opportunities\n",
      "  Processed 4000/8800 opportunities\n",
      "  Processed 4500/8800 opportunities\n",
      "  Processed 5000/8800 opportunities\n",
      "  Processed 5500/8800 opportunities\n",
      "  Processed 6000/8800 opportunities\n",
      "  Processed 6500/8800 opportunities\n",
      "  Processed 7000/8800 opportunities\n",
      "  Processed 7500/8800 opportunities\n",
      "  Processed 8000/8800 opportunities\n",
      "  Processed 8500/8800 opportunities\n",
      "Added 8800 opportunities!\n"
     ]
    }
   ],
   "source": [
    "# Adding opportunities to vector database\n",
    "\n",
    "for idx, row in pipeline.iterrows():\n",
    "    text = row['search_text']\n",
    "    embedding = model.encode(text).tolist()\n",
    "    \n",
    "    opportunities_collection.add(\n",
    "        embeddings=[embedding],\n",
    "        documents=[text],\n",
    "        metadatas=[{\n",
    "            'opportunity_id': str(row['opportunity_id']),\n",
    "            'sales_agent': str(row['sales_agent']),\n",
    "            'product': str(row['product']),\n",
    "            'account': str(row['account']),\n",
    "            'deal_stage': str(row['deal_stage']),\n",
    "            'close_value': str(row['close_value'])\n",
    "        }],\n",
    "        ids=[f\"opp_{idx}\"]\n",
    "    )\n",
    "    \n",
    "    if (idx + 1) % 500 == 0:\n",
    "        print(f\"  Processed {idx + 1}/{len(pipeline)} opportunities\")\n",
    "\n",
    "print(f\"Added {len(pipeline)} opportunities!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f33452",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50247feb",
   "metadata": {},
   "source": [
    "## Step 8: Making Search Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5a04b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_accounts(query, n_results=5, filter_sector=None):\n",
    "    \"\"\"\n",
    "    Search for accounts using natural language.\n",
    "    \n",
    "    Args:\n",
    "        query: What you're looking for (e.g., \"technology companies\")\n",
    "        n_results: How many results to return\n",
    "        filter_sector: Optional filter by industry sector\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with search results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Convert query to embedding\n",
    "        query_embedding = model.encode(query).tolist()\n",
    "        \n",
    "        # Search with optional filtering\n",
    "        if filter_sector:\n",
    "            results = accounts_collection.query(\n",
    "                query_embeddings=[query_embedding],\n",
    "                n_results=n_results,\n",
    "                where={\"sector\": filter_sector}\n",
    "            )\n",
    "        else:\n",
    "            results = accounts_collection.query(\n",
    "                query_embeddings=[query_embedding],\n",
    "                n_results=n_results\n",
    "            )\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Search error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8186f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_opportunities(query, n_results=5, filter_stage=None):\n",
    "    \"\"\"\n",
    "    Search for opportunities using natural language.\n",
    "    \n",
    "    Args:\n",
    "        query: What you're looking for (e.g., \"high value deals\")\n",
    "        n_results: How many results to return\n",
    "        filter_stage: Optional filter by deal stage\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with search results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query_embedding = model.encode(query).tolist()\n",
    "        \n",
    "        if filter_stage:\n",
    "            results = opportunities_collection.query(\n",
    "                query_embeddings=[query_embedding],\n",
    "                n_results=n_results,\n",
    "                where={\"deal_stage\": filter_stage}\n",
    "            )\n",
    "        else:\n",
    "            results = opportunities_collection.query(\n",
    "                query_embeddings=[query_embedding],\n",
    "                n_results=n_results\n",
    "            )\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Search error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ae080dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_account_results(results):\n",
    "    \"\"\"Helper function to display account results nicely.\"\"\"\n",
    "    if not results or not results['metadatas'][0]:\n",
    "        print(\"No results found.\")\n",
    "        return\n",
    "    \n",
    "    for i, metadata in enumerate(results['metadatas'][0]):\n",
    "        print(f\"\\n{i+1}. {metadata['account']}\")\n",
    "        print(f\"   Sector: {metadata['sector']}\")\n",
    "        print(f\"   Revenue: ${metadata['revenue']} million\")\n",
    "        print(f\"   Location: {metadata['location']}\")\n",
    "        print(f\"   Employees: {metadata['employees']}\")\n",
    "\n",
    "def pretty_print_opportunity_results(results):\n",
    "    \"\"\"Helper function to display opportunity results nicely.\"\"\"\n",
    "    if not results or not results['metadatas'][0]:\n",
    "        print(\"No results found.\")\n",
    "        return\n",
    "    \n",
    "    for i, metadata in enumerate(results['metadatas'][0]):\n",
    "        print(f\"\\n{i+1}. {metadata['opportunity_id']}\")\n",
    "        print(f\"   Agent: {metadata['sales_agent']}\")\n",
    "        print(f\"   Product: {metadata['product']}\")\n",
    "        print(f\"   Account: {metadata['account']}\")\n",
    "        print(f\"   Stage: {metadata['deal_stage']}\")\n",
    "        print(f\"   Value: ${metadata['close_value']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bf924e",
   "metadata": {},
   "source": [
    "## Testing the Semantic Search Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d9dd844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEST 1: Technology companies with high revenue\n",
      "\n",
      "1. bluth_company\n",
      "   Sector: technology\n",
      "   Revenue: $1242.32 million\n",
      "   Location: united_states\n",
      "   Employees: 3027.0\n",
      "\n",
      "2. konex\n",
      "   Sector: technology\n",
      "   Revenue: $7708.38 million\n",
      "   Location: united_states\n",
      "   Employees: 13756.0\n",
      "\n",
      "3. acme_corporation\n",
      "   Sector: technology\n",
      "   Revenue: $1100.04 million\n",
      "   Location: united_states\n",
      "   Employees: 2822.0\n",
      "\n",
      "\n",
      "TEST 2: Won deals by Darcel Schlecht\n",
      "\n",
      "1. tpnu79c1\n",
      "   Agent: darcel_schlecht\n",
      "   Product: mg_special\n",
      "   Account: toughzap\n",
      "   Stage: won\n",
      "   Value: $54.0\n",
      "\n",
      "2. ujsfg18f\n",
      "   Agent: darcel_schlecht\n",
      "   Product: mg_advanced\n",
      "   Account: dontechi\n",
      "   Stage: won\n",
      "   Value: $3290.0\n",
      "\n",
      "3. snfw1fd7\n",
      "   Agent: darcel_schlecht\n",
      "   Product: mg_advanced\n",
      "   Account: streethex\n",
      "   Stage: won\n",
      "   Value: $3369.0\n",
      "\n",
      "\n",
      "TEST 3: Medical sector accounts\n",
      "\n",
      "1. the_new_york_inquirer\n",
      "   Sector: medical\n",
      "   Revenue: $439.21 million\n",
      "   Location: united_states\n",
      "   Employees: 792.0\n",
      "\n",
      "2. bioplex\n",
      "   Sector: medical\n",
      "   Revenue: $326.82 million\n",
      "   Location: united_states\n",
      "   Employees: 1016.0\n",
      "\n",
      "3. lexiqvolax\n",
      "   Sector: medical\n",
      "   Revenue: $1618.89 million\n",
      "   Location: united_states\n",
      "   Employees: 3889.0\n"
     ]
    }
   ],
   "source": [
    "# Test 1: Search for accounts\n",
    "print(\"\\nTEST 1: Technology companies with high revenue\")\n",
    "results = search_accounts(\"technology companies high revenue\", n_results=3)\n",
    "pretty_print_account_results(results)\n",
    "\n",
    "# Test 2: Search for opportunities\n",
    "print(\"\\n\\nTEST 2: Won deals by Darcel Schlecht\") # Chose name randomly lol\n",
    "results = search_opportunities(\"won deals Darcel Schlecht\", n_results=3)\n",
    "pretty_print_opportunity_results(results)\n",
    "\n",
    "# Test 3: Search for medical sector accounts\n",
    "print(\"\\n\\nTEST 3: Medical sector accounts\")\n",
    "results = search_accounts(\"medical healthcare companies\", n_results=3)\n",
    "pretty_print_account_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df4df85",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
