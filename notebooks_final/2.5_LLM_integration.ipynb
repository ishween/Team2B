{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "464d2188",
   "metadata": {},
   "source": [
    "# LLM Integration Description\n",
    "LLM Integration refers to incorporation LLMs, in this case, Gemini, into businesses processes for enhanced efficiency, allowing for applications to leverage advanced NLP capabilites for a wide range of tasks.\n",
    "\n",
    "Some key concepts include...\n",
    "* API CAlls\n",
    "* Prompt Engineering\n",
    "* Data Handeling\n",
    "* RAG\n",
    "\n",
    "In this portion of the project, we are aiming to conduct LLM integration through: \n",
    "* Lead Scoring - identify and prioritize high value leads\n",
    "* Account Health - detects churn risks or upsell opportunities\n",
    "* Semantic Search - make chatbot retrieve and respond intelligently to business or sales data\n",
    "\n",
    "### Gemini: What is it?\n",
    "Gemini is an LLM developed by Google that allows for reasoning, code generation, and instruction following. \n",
    "\n",
    "### API - Application Programming Interface\n",
    "API will help us bridge between the LLM and the sent request. The API Key is a password that identifies the project when you use an APi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9261bdb7",
   "metadata": {},
   "source": [
    "## Step 1: Install Packages and Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbf8b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install Gemini\n",
    "# pip install google-generativeai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc3b1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to Gemini API\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables .env\n",
    "load_dotenv()\n",
    "\n",
    "# Get the Gemini API key from .env\n",
    "api_key = os.getenv('GEMINI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ed107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.10) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "DefaultCredentialsError",
     "evalue": "\n  No API_KEY or ADC found. Please either:\n    - Set the `GOOGLE_API_KEY` environment variable.\n    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\n    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m genai\u001b[38;5;241m.\u001b[39mconfigure(api_key\u001b[38;5;241m=\u001b[39mapi_key)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Debug: Print available models\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable models:\u001b[39m\u001b[38;5;124m\"\u001b[39m, [m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m genai\u001b[38;5;241m.\u001b[39mlist_models()])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Create the model with correct name\u001b[39;00m\n\u001b[1;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/gemini-pro-latest\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Update model name to match available models\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 16\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m genai\u001b[38;5;241m.\u001b[39mconfigure(api_key\u001b[38;5;241m=\u001b[39mapi_key)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Debug: Print available models\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable models:\u001b[39m\u001b[38;5;124m\"\u001b[39m, [m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m genai\u001b[38;5;241m.\u001b[39mlist_models()])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Create the model with correct name\u001b[39;00m\n\u001b[1;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/gemini-pro-latest\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Update model name to match available models\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/generativeai/models.py:202\u001b[0m, in \u001b[0;36mlist_models\u001b[0;34m(page_size, client, request_options)\u001b[0m\n\u001b[1;32m    199\u001b[0m     request_options \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[43mget_default_model_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m client\u001b[38;5;241m.\u001b[39mlist_models(page_size\u001b[38;5;241m=\u001b[39mpage_size, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options):\n\u001b[1;32m    205\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;241m.\u001b[39mto_dict(model)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/generativeai/client.py:372\u001b[0m, in \u001b[0;36mget_default_model_client\u001b[0;34m()\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_default_model_client\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m glm\u001b[38;5;241m.\u001b[39mModelServiceAsyncClient:\n\u001b[0;32m--> 372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_client_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_client\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/generativeai/client.py:289\u001b[0m, in \u001b[0;36m_ClientManager.get_default_client\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    287\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclients\u001b[38;5;241m.\u001b[39mget(name)\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 289\u001b[0m     client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclients[name] \u001b[38;5;241m=\u001b[39m client\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m client\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/generativeai/client.py:249\u001b[0m, in \u001b[0;36m_ClientManager.make_client\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ga_exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    243\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  No API_KEY or ADC found. Please either:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    - Set the `GOOGLE_API_KEY` environment variable.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    248\u001b[0m     )\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata:\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m client\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/generativeai/client.py:241\u001b[0m, in \u001b[0;36m_ClientManager.make_client\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m patch_colab_gce_credentials():\n\u001b[0;32m--> 241\u001b[0m         client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ga_exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    243\u001b[0m     e\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  No API_KEY or ADC found. Please either:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    - Set the `GOOGLE_API_KEY` environment variable.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    248\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/model_service/client.py:661\u001b[0m, in \u001b[0;36mModelServiceClient.__init__\u001b[0;34m(self, credentials, transport, client_options, client_info)\u001b[0m\n\u001b[1;32m    653\u001b[0m     transport_init: Union[\n\u001b[1;32m    654\u001b[0m         Type[ModelServiceTransport], Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, ModelServiceTransport]\n\u001b[1;32m    655\u001b[0m     ] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m cast(Callable[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, ModelServiceTransport], transport)\n\u001b[1;32m    659\u001b[0m     )\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;66;03m# initialize with the provided callable or the passed in class\u001b[39;00m\n\u001b[0;32m--> 661\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport \u001b[38;5;241m=\u001b[39m \u001b[43mtransport_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_cert_source_for_mtls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_cert_source\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masync\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transport):\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m CLIENT_LOGGING_SUPPORTED \u001b[38;5;129;01mand\u001b[39;00m _LOGGER\u001b[38;5;241m.\u001b[39misEnabledFor(\n\u001b[1;32m    675\u001b[0m         std_logging\u001b[38;5;241m.\u001b[39mDEBUG\n\u001b[1;32m    676\u001b[0m     ):  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/model_service/transports/grpc.py:239\u001b[0m, in \u001b[0;36mModelServiceGrpcTransport.__init__\u001b[0;34m(self, host, credentials, credentials_file, scopes, channel, api_mtls_endpoint, client_cert_source, ssl_channel_credentials, client_cert_source_for_mtls, quota_project_id, client_info, always_use_jwt_access, api_audience)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl_channel_credentials \u001b[38;5;241m=\u001b[39m grpc\u001b[38;5;241m.\u001b[39mssl_channel_credentials(\n\u001b[1;32m    235\u001b[0m                 certificate_chain\u001b[38;5;241m=\u001b[39mcert, private_key\u001b[38;5;241m=\u001b[39mkey\n\u001b[1;32m    236\u001b[0m             )\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# The base transport sets the host, credentials and scopes\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredentials_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcredentials_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscopes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscopes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malways_use_jwt_access\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_audience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_audience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grpc_channel:\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# initialize with the provided callable or the default channel\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     channel_init \u001b[38;5;241m=\u001b[39m channel \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreate_channel\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/model_service/transports/base.py:103\u001b[0m, in \u001b[0;36mModelServiceTransport.__init__\u001b[0;34m(self, host, credentials, credentials_file, scopes, quota_project_id, client_info, always_use_jwt_access, api_audience, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m google\u001b[38;5;241m.\u001b[39mauth\u001b[38;5;241m.\u001b[39mload_credentials_from_file(\n\u001b[1;32m    100\u001b[0m         credentials_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscopes_kwargs, quota_project_id\u001b[38;5;241m=\u001b[39mquota_project_id\n\u001b[1;32m    101\u001b[0m     )\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m credentials \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ignore_credentials:\n\u001b[0;32m--> 103\u001b[0m     credentials, _ \u001b[38;5;241m=\u001b[39m \u001b[43mgoogle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mscopes_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquota_project_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquota_project_id\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# Don't apply audience if the credentials file passed from user.\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(credentials, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith_gdch_audience\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/auth/_default.py:739\u001b[0m, in \u001b[0;36mdefault\u001b[0;34m(scopes, request, quota_project_id, default_scopes)\u001b[0m\n\u001b[1;32m    731\u001b[0m             _LOGGER\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    732\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo project ID could be determined. Consider running \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    733\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`gcloud config set project` or setting the \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    734\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    735\u001b[0m                 environment_vars\u001b[38;5;241m.\u001b[39mPROJECT,\n\u001b[1;32m    736\u001b[0m             )\n\u001b[1;32m    737\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m credentials, effective_project_id\n\u001b[0;32m--> 739\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mDefaultCredentialsError(_CLOUD_SDK_MISSING_CREDENTIALS)\n",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m: \n  No API_KEY or ADC found. Please either:\n    - Set the `GOOGLE_API_KEY` environment variable.\n    - Manually pass the key with `genai.configure(api_key=my_api_key)`.\n    - Or set up Application Default Credentials, see https://ai.google.dev/gemini-api/docs/oauth for more information."
     ]
    }
   ],
   "source": [
    "#initialize Gemini and import necessary libraries\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Dict, Any, List, Optional\n",
    "\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import joblib\n",
    "\n",
    "# Configure Gemini with your API key\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Debug: Print available models\n",
    "print(\"Available models:\", [m.name for m in genai.list_models()])\n",
    "\n",
    "# Create the model with correct name\n",
    "model = genai.GenerativeModel('models/gemini-pro-latest')  # Update model name to match available models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd468b3e",
   "metadata": {},
   "source": [
    "## Step 2: Create Helper Funcitons for Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32f367e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GBDTLeadScorer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        pipeline=None,\n",
    "        features: Optional[List[str]] = None,\n",
    "        model_path: Optional[str] = None,\n",
    "        feature_path: Optional[str] = None,\n",
    "    ):\n",
    "        if pipeline is not None:\n",
    "            self.pipeline = pipeline\n",
    "        elif model_path and os.path.exists(model_path):\n",
    "            self.pipeline = joblib.load(model_path)\n",
    "        else:\n",
    "            raise ValueError(\"Provide a fitted pipeline or a valid model_path.\")\n",
    "\n",
    "        # Prefer explicit features arg; else try load from file; else None\n",
    "        if features is not None:\n",
    "            self.features = features\n",
    "        elif feature_path and os.path.exists(feature_path):\n",
    "            self.features = joblib.load(feature_path)\n",
    "        else:\n",
    "            self.features = None  # pipeline must handle missing order\n",
    "\n",
    "    def predict(self, features: Dict[str, Any]) -> float:\n",
    "        X = pd.DataFrame([features])\n",
    "        if self.features:\n",
    "            X = X.reindex(columns=self.features)\n",
    "        proba = self.pipeline.predict_proba(X)[:, 1]\n",
    "        return float(proba[0])\n",
    "\n",
    "\n",
    "class AccountHealthScorer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        pipeline=None,\n",
    "        features: Optional[List[str]] = None,\n",
    "        model_path: Optional[str] = None,\n",
    "        feature_path: Optional[str] = None,\n",
    "    ):\n",
    "        if pipeline is not None:\n",
    "            self.pipeline = pipeline\n",
    "        elif model_path and os.path.exists(model_path):\n",
    "            self.pipeline = joblib.load(model_path)\n",
    "        else:\n",
    "            raise ValueError(\"Provide a fitted pipeline or a valid model_path.\")\n",
    "\n",
    "        if features is not None:\n",
    "            self.features = features\n",
    "        elif feature_path and os.path.exists(feature_path):\n",
    "            self.features = joblib.load(feature_path)\n",
    "        else:\n",
    "            self.features = None\n",
    "\n",
    "    def predict(self, features: Dict[str, Any]) -> float:\n",
    "        X = pd.DataFrame([features])\n",
    "        if self.features:\n",
    "            X = X.reindex(columns=self.features)\n",
    "        proba = self.pipeline.predict_proba(X)[:, 1]  # adjust if needed\n",
    "        return float(proba[0])\n",
    "\n",
    "\n",
    "class SemanticSearcher:\n",
    "    \"\"\"Use an existing Chroma collection/client if you already created one.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        collection=None,\n",
    "        client=None,\n",
    "        persist_dir: Optional[str] = None,\n",
    "        collection_name: str = \"crm_docs\",\n",
    "    ):\n",
    "        if collection is not None:\n",
    "            self.collection = collection\n",
    "        else:\n",
    "            if client is None:\n",
    "                if not persist_dir:\n",
    "                    raise ValueError(\"Provide collection/client OR persist_dir.\")\n",
    "                import chromadb\n",
    "                client = chromadb.PersistentClient(path=persist_dir)\n",
    "            self.collection = client.get_or_create_collection(collection_name)\n",
    "\n",
    "    def search(self, query: str, n_results: int = 5, where: Optional[Dict[str, Any]] = None):\n",
    "        res = self.collection.query(query_texts=[query], n_results=n_results, where=where)\n",
    "        docs = res.get(\"documents\", [[]])[0]\n",
    "        metas = res.get(\"metadatas\", [[]])[0]\n",
    "        dists = res.get(\"distances\", [[]])[0] if \"distances\" in res else [None]*len(docs)\n",
    "        out = []\n",
    "        for i, txt in enumerate(docs):\n",
    "            meta = metas[i] if i < len(metas) else {}\n",
    "            out.append({\n",
    "                \"text\": txt,\n",
    "                \"source\": (meta or {}).get(\"source\", f\"doc_{i}\"),\n",
    "                \"score\": dists[i]\n",
    "            })\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f560755f",
   "metadata": {},
   "source": [
    "## Step 3: Create Main Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f639ec6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\"GEMINI_API_KEY not set in your .env\")\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "class CRMAssistant:\n",
    "    def __init__(self, lead_scorer, health_scorer, semantic_searcher, model_name=\"gemini-pro\"):\n",
    "        self.lead_scorer = lead_scorer\n",
    "        self.health_scorer = health_scorer\n",
    "        self.semantic_searcher = semantic_searcher\n",
    "        self.model = genai.GenerativeModel(model_name)\n",
    "\n",
    "    @staticmethod\n",
    "    def _fmt(docs: List[Dict[str, Any]]) -> str:\n",
    "        return \"\\n\".join(f\"[{d.get('source','doc')}] {d.get('text','')}\" for d in docs)\n",
    "\n",
    "    def process_lead_score(self, lead_score: float, lead_data: Dict[str, Any]) -> str:\n",
    "        prompt = f\"\"\"\n",
    "You are a CRM assistant. Given a lead score of {lead_score:.2f} and this lead data:\n",
    "{lead_data}\n",
    "\n",
    "Provide:\n",
    "- 2–4 next actions,\n",
    "- a short rationale referencing top drivers,\n",
    "- a one-line priority (High/Med/Low).\n",
    "\"\"\"\n",
    "        return self.model.generate_content(prompt).text\n",
    "\n",
    "    def analyze_account_health(self, health_score: float, account_data: Dict[str, Any]) -> str:\n",
    "        prompt = f\"\"\"\n",
    "You are a CRM assistant. Account health score: {health_score:.2f}.\n",
    "Account data:\n",
    "{account_data}\n",
    "\n",
    "Return:\n",
    "- 3 targeted recommendations,\n",
    "- key risks,\n",
    "- owner + due date for the first action.\n",
    "\"\"\"\n",
    "        return self.model.generate_content(prompt).text\n",
    "\n",
    "    def semantic_search_response(self, query: str, context_docs: List[Dict[str, Any]]) -> str:\n",
    "        ctx = self._fmt(context_docs)\n",
    "        prompt = f\"\"\"\n",
    "Use the CRM context to answer. If info is missing, say what is needed.\n",
    "\n",
    "Context:\n",
    "{ctx}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Reply with a brief summary and bullet points. Cite sources in [brackets].\n",
    "\"\"\"\n",
    "        return self.model.generate_content(prompt).text\n",
    "\n",
    "    def process_query(self, query: str, context: Optional[Dict[str, Any]] = None) -> str:\n",
    "        q = query.lower()\n",
    "        if \"lead\" in q and any(k in q for k in [\"score\", \"convert\", \"probability\"]):\n",
    "            if context is None:\n",
    "                return \"I need lead features (or a lead_id I can fetch) to score this lead.\"\n",
    "            score = self.lead_scorer.predict(context)\n",
    "            return self.process_lead_score(score, context)\n",
    "\n",
    "        if any(k in q for k in [\"health\", \"churn\", \"risk\", \"renewal\"]):\n",
    "            if context is None:\n",
    "                return \"I need account features (or an account_id I can fetch) to assess health.\"\n",
    "            score = self.health_scorer.predict(context)\n",
    "            return self.analyze_account_health(score, context)\n",
    "\n",
    "        docs = self.semantic_searcher.search(query)\n",
    "        return self.semantic_search_response(query, docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0759ddb4",
   "metadata": {},
   "source": [
    "## Step 4: Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b03caa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing Gemini LLM Integration ===\n",
      "\n",
      "Prompt: What are the key benefits of using LLMs in CRM systems?\n",
      "\n",
      "Response: Of course. Integrating Large Language Models (LLMs) into Customer Relationship Management (CRM) systems is a transformative shift, turning CRMs from passive systems of record into proactive, intelligent partners.\n",
      "\n",
      "The key benefits can be grouped into four main areas: **Supercharging Sales Teams**, **Revolutionizing Customer Service**, **Enhancing Marketing Personalization**, and **Boosting Overall Operational Efficiency**.\n",
      "\n",
      "Here’s a detailed breakdown of the key benefits in each area:\n",
      "\n",
      "---\n",
      "\n",
      "### 1. Supercharging Sales Teams\n",
      "\n",
      "LLMs act as a \"co-pilot\" for sales representatives, automating tedious tasks and providing intelligent guidance to help them close deals faster.\n",
      "\n",
      "*   **Automated Communication & Content Generation:**\n",
      "    *   **Benefit:** Dramatically reduces the time spent on writing. Sales reps can instantly generate personalized outreach emails, follow-up messages, and meeting preparation notes based on a customer's profile, industry, and past interactions.\n",
      "    *   **Example:** A sales rep clicks a button on a lead's profile, and the LLM drafts a compelling introductory email that references the lead's recent activity on LinkedIn and mentions a relevant case study.\n",
      "\n",
      "*   **Intelligent Summarization:**\n",
      "    *   **Benefit:** Saves hours of reading and helps reps get up to speed instantly. LLMs can summarize long email threads, call transcripts, and meeting notes into concise, actionable bullet points.\n",
      "    *   **Example:** A new account executive takes over a deal. Instead of reading dozens of emails, they get an LLM-generated summary: \"Customer is concerned about integration with SAP, is price-sensitive, and the key decision-maker is Jane Doe. Next step is to schedule a technical demo.\"\n",
      "\n",
      "*   **Real-time Sales Coaching and Guidance:**\n",
      "    *   **Benefit:** Improves sales effectiveness and consistency. During a live call or while drafting an email, the LLM can analyze the conversation and suggest talking points, answers to objections, or relevant product information in real-time.\n",
      "    *   **Example:** A customer says, \"Your competitor is 20% cheaper.\" The LLM instantly surfaces a battle card highlighting key differentiators and value propositions to counter the objection.\n",
      "\n",
      "*   **Enhanced Lead Scoring and Opportunity Insights:**\n",
      "    *   **Benefit:** Focuses sales efforts on the most promising deals. By analyzing the sentiment and content of customer communications, LLMs can identify buying signals (e.g., use of words like \"budget,\" \"timeline,\" \"proposal\") or risks (e.g., mentions of competitors, frustration) that traditional scoring misses.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. Revolutionizing Customer Service\n",
      "\n",
      "LLMs empower support agents to resolve issues faster and provide a more empathetic, human-like experience for customers.\n",
      "\n",
      "*   **Advanced, Human-like Chatbots & Virtual Agents:**\n",
      "    *   **Benefit:** Provides instant, 24/7 support that can handle complex, multi-turn conversations, unlike rigid, rule-based bots. This frees up human agents for the most critical issues.\n",
      "    *   **Example:** A customer can ask a chatbot, \"I ordered a blue shirt last week but it hasn't arrived, and I think I used the wrong address.\" The LLM-powered bot can understand the entire context, look up the order, identify the address issue, and guide the customer through correcting it.\n",
      "\n",
      "*   **Agent Assist & Co-pilot:**\n",
      "    *   **Benefit:** Increases agent productivity and reduces response times. While an agent is talking to a customer, the LLM can listen in, automatically find relevant knowledge base articles, and draft accurate, empathetic responses for the agent to review and send.\n",
      "    *   **Example:** As a customer describes a technical problem, the LLM surfaces the exact troubleshooting guide and pre-writes a step-by-step response, cutting the agent's research and typing time by over 50%.\n",
      "\n",
      "*   **Automated Case Summarization and Categorization:**\n",
      "    *   **Benefit:** Ensures faster routing and resolution. When a support ticket arrives, the LLM instantly reads the customer's message, summarizes the core issue, and automatically categorizes and routes it to the correct department (e.g., Billing, Technical Support, Returns).\n",
      "\n",
      "---\n",
      "\n",
      "### 3. Enhancing Marketing Personalization\n",
      "\n",
      "LLMs allow marketers to move beyond basic segmentation and create truly one-to-one marketing campaigns at scale.\n",
      "\n",
      "*   **Hyper-Personalized Campaign Content:**\n",
      "    *   **Benefit:** Boosts engagement and conversion rates. Marketers can use LLMs to generate thousands of variations of ad copy, email subject lines, and body content, each tailored to a specific customer segment's interests, past purchases, and browsing history.\n",
      "    *   **Example:** An e-commerce company can generate an email campaign where each customer sees a unique product description that highlights the features most relevant to them, based on their previous interactions.\n",
      "\n",
      "*   **Deeper Sentiment Analysis & Voice of the Customer (VoC):**\n",
      "    *   **Benefit:** Provides a real-time pulse on customer perception. LLMs can analyze thousands of customer reviews, social media comments, and survey responses to identify emerging trends, product issues, or positive feedback with a level of nuance that keyword-based tools can't match.\n",
      "\n",
      "*   **Intelligent Audience Segmentation:**\n",
      "    *   **Benefit:** Enables highly specific targeting without complex queries. Marketers can use natural language to define new audience segments.\n",
      "    *   **Example:** A marketer could simply ask the CRM, \"Create a list of all customers who have purchased product X, haven't logged in for 90 days, and have mentioned 'poor user interface' in a support ticket.\"\n",
      "\n",
      "---\n",
      "\n",
      "### 4. Boosting Overall Operational Efficiency & Data Analytics\n",
      "\n",
      "LLMs make the CRM itself easier to use and unlock the value hidden within its data for everyone, not just analysts.\n",
      "\n",
      "*   **Natural Language Data Querying:**\n",
      "    *   **Benefit:** Democratizes data access. Any user, regardless of technical skill, can ask complex questions about their data in plain English and get instant reports, charts, and answers.\n",
      "    *   **Example:** A sales manager can ask, \"What was our total revenue in the West region last quarter, and how does that compare to the year before?\" instead of needing to build a custom report.\n",
      "\n",
      "*   **Automated Data Entry and Cleansing:**\n",
      "    *   **Benefit:** Improves data quality and saves administrative time. LLMs can extract structured information from unstructured text, such as automatically creating a new contact record from an email signature or updating an opportunity stage based on the content of a sales call summary.\n",
      "\n",
      "*   **Predictive Analytics and Forecasting:**\n",
      "    *   **Benefit:** Provides more accurate and data-driven business planning. By analyzing historical trends and the text within deal notes, LLMs can help generate more reliable sales forecasts and identify at-risk customers before they churn.\n",
      "\n",
      "### Summary Table: Key Benefits at a Glance\n",
      "\n",
      "| Category | Specific Benefit | Impact |\n",
      "| :--- | :--- | :--- |\n",
      "| **Sales** | Automated Content Generation | Saves time, increases outreach volume and quality. |\n",
      "| | Intelligent Summarization | Faster onboarding, quicker deal handoffs. |\n",
      "| | Real-time Coaching | Improves win rates, more effective reps. |\n",
      "| **Customer Service** | Advanced Chatbots | 24/7 support, lower operational costs. |\n",
      "| | Agent Assist (Co-pilot) | Faster resolution times (FCR), higher agent satisfaction. |\n",
      "| | Automated Case Routing | Reduces manual work, quicker response to customers. |\n",
      "| **Marketing** | Hyper-Personalization | Higher engagement, better conversion rates. |\n",
      "| | Sentiment Analysis | Proactive issue resolution, deeper customer understanding. |\n",
      "| | Intelligent Segmentation | More effective and targeted campaigns. |\n",
      "| **Operations** | Natural Language Querying | Empowers non-technical users to access data insights. |\n",
      "| | Automated Data Entry | Better data hygiene, less administrative overhead. |\n",
      "| | Predictive Forecasting | More accurate business planning and resource allocation. |\n",
      "\n",
      "In conclusion, the integration of LLMs fundamentally changes the value proposition of a CRM. It evolves from a database for storing customer information into an intelligent engine that actively helps you build better relationships, close more deals, and operate more efficiently.\n",
      "\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "# Basic LLM Integration Test\n",
    "# Test function remains the same\n",
    "def test_llm_integration():\n",
    "    prompt = \"What are the key benefits of using LLMs in CRM systems?\"\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(\n",
    "            prompt,\n",
    "            generation_config={\n",
    "                \"temperature\": 0.7,\n",
    "                \"top_p\": 0.8,\n",
    "                \"top_k\": 40\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        print(\"\\n=== Testing Gemini LLM Integration ===\")\n",
    "        print(\"\\nPrompt:\", prompt)\n",
    "        print(\"\\nResponse:\", response.text)\n",
    "        print(\"\\n=====================================\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error testing LLM integration: {str(e)}\")\n",
    "        print(\"API Key configured:\", bool(api_key))\n",
    "        print(\"Available models:\", [m.name for m in genai.list_models()])\n",
    "\n",
    "# Run the test\n",
    "test_llm_integration()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
