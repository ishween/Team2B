{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61135412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.2-cp39-cp39-macosx_11_0_arm64.whl (10.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.8 MB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[K     |████████████████████████████████| 347 kB 30.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting numpy>=1.22.4\n",
      "  Downloading numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.3 MB 37.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[K     |████████████████████████████████| 509 kB 53.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.15.0)\n",
      "Installing collected packages: tzdata, pytz, numpy, pandas\n",
      "Successfully installed numpy-2.0.2 pandas-2.3.2 pytz-2025.2 tzdata-2025.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a03a5d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /Users/apple/Library/Python/3.9/lib/python/site-packages (2.0.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e9f746c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.4-cp39-cp39-macosx_11_0_arm64.whl (7.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.8 MB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.0.2)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 11.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=8\n",
      "  Downloading pillow-11.3.0-cp39-cp39-macosx_11_0_arm64.whl (4.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.7 MB 41.5 MB/s eta 0:00:01     |███████████▎                    | 1.6 MB 41.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.59.2-cp39-cp39-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 19.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 21.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources>=3.2.0\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.0-cp39-cp39-macosx_11_0_arm64.whl (249 kB)\n",
      "\u001b[K     |████████████████████████████████| 249 kB 22.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /Users/apple/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.18.1)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.0 cycler-0.12.1 fonttools-4.59.2 importlib-resources-6.5.2 kiwisolver-1.4.7 matplotlib-3.9.4 pillow-11.3.0 pyparsing-3.2.3\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.2 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6ba886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6ee84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts = pd.read_csv(\"accounts.csv\")\n",
    "data_dict = pd.read_csv(\"data_dictionary.csv\")\n",
    "products = pd.read_csv(\"products.csv\")\n",
    "sales_pipeline = pd.read_csv(\"sales_pipeline.csv\")\n",
    "sales_teams = pd.read_csv(\"sales_teams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa9a42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ACCOUNTS ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85 entries, 0 to 84\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   account           85 non-null     object \n",
      " 1   sector            85 non-null     object \n",
      " 2   year_established  85 non-null     int64  \n",
      " 3   revenue           85 non-null     float64\n",
      " 4   employees         85 non-null     int64  \n",
      " 5   office_location   85 non-null     object \n",
      " 6   subsidiary_of     15 non-null     object \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 4.8+ KB\n",
      "None\n",
      "            account     sector  year_established  revenue  employees  \\\n",
      "0  Acme Corporation  technolgy              1996  1100.04       2822   \n",
      "1        Betasoloin    medical              1999   251.41        495   \n",
      "2          Betatech    medical              1986   647.18       1185   \n",
      "3        Bioholding    medical              2012   587.34       1356   \n",
      "4           Bioplex    medical              1991   326.82       1016   \n",
      "\n",
      "  office_location subsidiary_of  \n",
      "0   United States           NaN  \n",
      "1   United States           NaN  \n",
      "2           Kenya           NaN  \n",
      "3      Philipines           NaN  \n",
      "4   United States           NaN  \n",
      "\n",
      "--- PRODUCTS ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   product      7 non-null      object\n",
      " 1   series       7 non-null      object\n",
      " 2   sales_price  7 non-null      int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 296.0+ bytes\n",
      "None\n",
      "        product series  sales_price\n",
      "0     GTX Basic    GTX          550\n",
      "1       GTX Pro    GTX         4821\n",
      "2    MG Special     MG           55\n",
      "3   MG Advanced     MG         3393\n",
      "4  GTX Plus Pro    GTX         5482\n",
      "\n",
      "--- SALES_PIPELINE ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8800 entries, 0 to 8799\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   opportunity_id  8800 non-null   object \n",
      " 1   sales_agent     8800 non-null   object \n",
      " 2   product         8800 non-null   object \n",
      " 3   account         7375 non-null   object \n",
      " 4   deal_stage      8800 non-null   object \n",
      " 5   engage_date     8300 non-null   object \n",
      " 6   close_date      6711 non-null   object \n",
      " 7   close_value     6711 non-null   float64\n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 550.1+ KB\n",
      "None\n",
      "  opportunity_id      sales_agent         product  account deal_stage  \\\n",
      "0       1C1I7A6R      Moses Frase  GTX Plus Basic  Cancity        Won   \n",
      "1       Z063OYW0  Darcel Schlecht          GTXPro    Isdom        Won   \n",
      "2       EC4QE1BX  Darcel Schlecht      MG Special  Cancity        Won   \n",
      "3       MV1LWRNH      Moses Frase       GTX Basic  Codehow        Won   \n",
      "4       PE84CX4O        Zane Levy       GTX Basic   Hatfan        Won   \n",
      "\n",
      "  engage_date  close_date  close_value  \n",
      "0  2016-10-20  2017-03-01       1054.0  \n",
      "1  2016-10-25  2017-03-11       4514.0  \n",
      "2  2016-10-25  2017-03-07         50.0  \n",
      "3  2016-10-25  2017-03-09        588.0  \n",
      "4  2016-10-25  2017-03-02        517.0  \n",
      "\n",
      "--- SALES_TEAMS ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35 entries, 0 to 34\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   sales_agent      35 non-null     object\n",
      " 1   manager          35 non-null     object\n",
      " 2   regional_office  35 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 968.0+ bytes\n",
      "None\n",
      "         sales_agent           manager regional_office\n",
      "0      Anna Snelling  Dustin Brinkmann         Central\n",
      "1     Cecily Lampkin  Dustin Brinkmann         Central\n",
      "2  Versie Hillebrand  Dustin Brinkmann         Central\n",
      "3    Lajuana Vencill  Dustin Brinkmann         Central\n",
      "4        Moses Frase  Dustin Brinkmann         Central\n"
     ]
    }
   ],
   "source": [
    "# inspect data\n",
    "for name, df in {\n",
    "    \"accounts\": accounts,\n",
    "    \"products\": products,\n",
    "    \"sales_pipeline\": sales_pipeline,\n",
    "    \"sales_teams\": sales_teams\n",
    "}.items():\n",
    "    print(f\"\\n--- {name.upper()} ---\")\n",
    "    print(df.info())\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4b5018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize column names\n",
    "def clean_columns(df):\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "    return df\n",
    "\n",
    "accounts = clean_columns(accounts)\n",
    "products = clean_columns(products)\n",
    "sales_pipeline = clean_columns(sales_pipeline)\n",
    "sales_teams = clean_columns(sales_teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba6a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle duplicates\n",
    "accounts.drop_duplicates(inplace=True)\n",
    "products.drop_duplicates(inplace=True)\n",
    "sales_pipeline.drop_duplicates(inplace=True)\n",
    "sales_teams.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4ca547",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zv/ft654ndd6nb8khhg3y2nqnth0000gn/T/ipykernel_44453/4282500350.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "/var/folders/zv/ft654ndd6nb8khhg3y2nqnth0000gn/T/ipykernel_44453/4282500350.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/zv/ft654ndd6nb8khhg3y2nqnth0000gn/T/ipykernel_44453/4282500350.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/zv/ft654ndd6nb8khhg3y2nqnth0000gn/T/ipykernel_44453/4282500350.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/zv/ft654ndd6nb8khhg3y2nqnth0000gn/T/ipykernel_44453/4282500350.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "/var/folders/zv/ft654ndd6nb8khhg3y2nqnth0000gn/T/ipykernel_44453/4282500350.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/zv/ft654ndd6nb8khhg3y2nqnth0000gn/T/ipykernel_44453/4282500350.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
      "/var/folders/zv/ft654ndd6nb8khhg3y2nqnth0000gn/T/ipykernel_44453/4282500350.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/var/folders/zv/ft654ndd6nb8khhg3y2nqnth0000gn/T/ipykernel_44453/4282500350.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# handle missing values\n",
    "def fill_missing(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype in [\"int64\", \"float64\"]:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "accounts = fill_missing(accounts)\n",
    "products = fill_missing(products)\n",
    "sales_pipeline = fill_missing(sales_pipeline)\n",
    "sales_teams = fill_missing(sales_teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "329895b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix date columns\n",
    "date_cols = [col for col in sales_pipeline.columns if \"date\" in col]\n",
    "for col in date_cols:\n",
    "    sales_pipeline[col] = pd.to_datetime(sales_pipeline[col], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e87fafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize currency columns\n",
    "currency_cols = [col for col in sales_pipeline.columns if \"amount\" in col or \"revenue\" in col]\n",
    "for col in currency_cols:\n",
    "    sales_pipeline[col] = (\n",
    "        sales_pipeline[col]\n",
    "        .astype(str)\n",
    "        .str.replace(r\"[$,]\", \"\", regex=True)\n",
    "        .astype(float)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3ae8434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize categorical values\n",
    "cat_cols = [col for col in accounts.columns if accounts[col].dtype == \"object\"]\n",
    "for col in cat_cols:\n",
    "    accounts[col] = accounts[col].str.strip().str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4b20a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned datasets\n",
    "accounts.to_csv(\"cleaned_accounts.csv\", index=False)\n",
    "products.to_csv(\"cleaned_products.csv\", index=False)\n",
    "sales_pipeline.to_csv(\"cleaned_sales_pipeline.csv\", index=False)\n",
    "sales_teams.to_csv(\"cleaned_sales_teams.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16d6714d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accounts duplicates: 0\n",
      "Products duplicates: 0\n",
      "Pipeline duplicates: 0\n",
      "Teams duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# check for duplicates\n",
    "print(\"Accounts duplicates:\", accounts.duplicated().sum())\n",
    "print(\"Products duplicates:\", products.duplicated().sum())\n",
    "print(\"Pipeline duplicates:\", sales_pipeline.duplicated().sum())\n",
    "print(\"Teams duplicates:\", sales_teams.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "970d078a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per dataset:\n",
      "\n",
      "ACCOUNTS\n",
      "account             0\n",
      "sector              0\n",
      "year_established    0\n",
      "revenue             0\n",
      "employees           0\n",
      "office_location     0\n",
      "subsidiary_of       0\n",
      "dtype: int64\n",
      "\n",
      "PRODUCTS\n",
      "product        0\n",
      "series         0\n",
      "sales_price    0\n",
      "dtype: int64\n",
      "\n",
      "SALES_PIPELINE\n",
      "opportunity_id    0\n",
      "sales_agent       0\n",
      "product           0\n",
      "account           0\n",
      "deal_stage        0\n",
      "engage_date       0\n",
      "close_date        0\n",
      "close_value       0\n",
      "dtype: int64\n",
      "\n",
      "SALES_TEAMS\n",
      "sales_agent        0\n",
      "manager            0\n",
      "regional_office    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check for missing values\n",
    "print(\"Missing values per dataset:\")\n",
    "for name, df in {\n",
    "    \"accounts\": accounts,\n",
    "    \"products\": products,\n",
    "    \"sales_pipeline\": sales_pipeline,\n",
    "    \"sales_teams\": sales_teams\n",
    "}.items():\n",
    "    print(f\"\\n{name.upper()}\")\n",
    "    print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38292dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opportunity_id            object\n",
      "sales_agent               object\n",
      "product                   object\n",
      "account                   object\n",
      "deal_stage                object\n",
      "engage_date       datetime64[ns]\n",
      "close_date        datetime64[ns]\n",
      "close_value              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# check data types\n",
    "print(sales_pipeline.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "470cf875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "account: ['Acme Corporation' 'Betasoloin' 'Betatech' 'Bioholding' 'Bioplex'\n",
      " 'Blackzim' 'Bluth Company' 'Bubba Gump' 'Cancity' 'Cheers']\n",
      "\n",
      "sector: ['Technolgy' 'Medical' 'Retail' 'Software' 'Entertainment' 'Marketing'\n",
      " 'Telecommunications' 'Finance' 'Employment' 'Services']\n",
      "\n",
      "office_location: ['United States' 'Kenya' 'Philipines' 'Japan' 'Italy' 'Norway' 'Korea'\n",
      " 'Jordan' 'Brazil' 'Germany']\n",
      "\n",
      "subsidiary_of: ['Acme Corporation' 'Massive Dynamic' 'Bubba Gump' 'Inity' 'Sonron'\n",
      " 'Golddex' 'Warephase']\n"
     ]
    }
   ],
   "source": [
    "# check categorical values\n",
    "for col in accounts.select_dtypes(include=\"object\").columns:\n",
    "    print(f\"\\n{col}: {accounts[col].unique()[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c80640f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         engage_date                     close_date  \\\n",
      "count                           8800                           8800   \n",
      "mean   2017-06-16 11:54:55.636363520  2017-07-15 06:11:37.090909184   \n",
      "min              2016-10-20 00:00:00            2017-03-01 00:00:00   \n",
      "25%              2017-04-07 00:00:00            2017-05-22 00:00:00   \n",
      "50%              2017-07-01 00:00:00            2017-06-13 00:00:00   \n",
      "75%              2017-08-22 00:00:00            2017-09-20 00:00:00   \n",
      "max              2017-12-27 00:00:00            2017-12-31 00:00:00   \n",
      "std                              NaN                            NaN   \n",
      "\n",
      "        close_value  \n",
      "count   8800.000000  \n",
      "mean    1249.038864  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%      472.000000  \n",
      "75%     1085.250000  \n",
      "max    30288.000000  \n",
      "std     2072.411434  \n"
     ]
    }
   ],
   "source": [
    "# check numeric ranges\n",
    "print(sales_pipeline.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712be5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualization to be made"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
