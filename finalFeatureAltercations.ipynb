{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-12T20:24:30.920028Z",
     "start_time": "2025-09-12T20:24:30.907657Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T21:12:01.149326Z",
     "start_time": "2025-09-12T21:12:01.104854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "accountFile = os.path.join(os.getcwd(), 'Datasets',\"accounts.csv\")\n",
    "dict_File = os.path.join(os.getcwd(), 'Datasets',\"data_dictionary.csv\")\n",
    "productsFile = os.path.join(os.getcwd(), 'Datasets',\"products.csv\")\n",
    "pipelineFile = os.path.join(os.getcwd(), 'Datasets',\"sales_pipeline.csv\")\n",
    "teamsFile = os.path.join(os.getcwd(), 'Datasets',\"sales_teams.csv\")\n",
    "\n",
    "df_accounts = pd.read_csv(accountFile)\n",
    "df_dictData = pd.read_csv(dict_File)\n",
    "df_products = pd.read_csv(productsFile)\n",
    "df_pipeline = pd.read_csv(pipelineFile)\n",
    "df_teams = pd.read_csv(teamsFile)"
   ],
   "id": "58f70ed01d3f072f",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T21:12:01.574439Z",
     "start_time": "2025-09-12T21:12:01.567976Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datasets = {\n",
    "    \"Accounts\" : df_accounts,\n",
    "    \"DictData\" : df_dictData,\n",
    "    \"Products\" : df_products,\n",
    "    \"Pipeline\" : df_pipeline,\n",
    "    \"Teams\" : df_teams\n",
    "}"
   ],
   "id": "bcb08a3819409192",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T21:12:01.995060Z",
     "start_time": "2025-09-12T21:12:01.985818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#standerizes the column names\n",
    "def standerizeColumnNames(dataDict_List):\n",
    "    for names, df in dataDict_List.items():\n",
    "        print(f\"standerizing columns {names}\")\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype == object:\n",
    "                df[col] = df[col].str.strip().str.lower().str.replace(' ','_')\n",
    "        print(f\"Completed: {names}\")"
   ],
   "id": "ff359eccce26fa68",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T21:12:02.405704Z",
     "start_time": "2025-09-12T21:12:02.396854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dataset_analysis(dataDict_List):\n",
    "    for name, df in dataDict_List.items():\n",
    "        print(f\"Missing Values for {name}\")\n",
    "        missingValues = df.isnull().sum()\n",
    "        missingValues = missingValues.sort_values(ascending=False)\n",
    "\n",
    "        print(missingValues)"
   ],
   "id": "51a3290633406fa1",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T21:12:02.766749Z",
     "start_time": "2025-09-12T21:12:02.756477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Note: when I use dataDict_List I refer to a list of dictionaries for our dataframes, every functionality changed in the dataset has its corresponding functions\n",
    "\n",
    "#performs median imputation which is the process of replacing each missing value with a numerical value that is the meadian of all the non-missing values; it also drops all duplicate values\n",
    "def clean_datasets(dataDict_List):\n",
    "    print(\"Cleaning Datasets\")\n",
    "    for df in dataDict_List.values():\n",
    "        #duplicates\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        #missing values\n",
    "        for col in df.columns:\n",
    "            if df[col].dtype in [\"int64\", \"float64\", \"number\"]:\n",
    "                median_values = df[col].median()\n",
    "                df[col] = df[col].fillna(median_values)\n",
    "            else:\n",
    "                mode = df[col].mode()[0]\n",
    "                df[col] = df[col].fillna(mode)\n",
    "\n",
    "    print(\"Dataset Cleaned\")\n"
   ],
   "id": "fa4be89445f405cd",
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T21:12:03.154955Z",
     "start_time": "2025-09-12T21:12:03.146102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#standardizes all dates in the dataset\n",
    "def standardize_dates(dataDict_List):\n",
    "    #standardize date\n",
    "    for df in dataDict_List.values():\n",
    "        for col in df.columns:\n",
    "            if \"date\" in col.lower():\n",
    "                df[col] = pd.to_datetime(df[col], errors=\"coerce\")"
   ],
   "id": "e8ff6a30074cd5e5",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T21:12:03.513790Z",
     "start_time": "2025-09-12T21:12:03.505484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def currency_standard(dataDict_List):\n",
    "    for df in dataDict_List.values():\n",
    "        for col in df.columns:\n",
    "            moneyColumns = [c for c in df.columns if \"amount\" in c or \"revenue\" in c]\n",
    "            for col in moneyColumns:\n",
    "                df[col] = df[col].astype(float)"
   ],
   "id": "cc9440c6e7c32fe7",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T21:12:03.890176Z",
     "start_time": "2025-09-12T21:12:03.867733Z"
    }
   },
   "cell_type": "code",
   "source": "dataset_analysis(datasets)",
   "id": "b932b512161f19e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values for Accounts\n",
      "subsidiary_of       70\n",
      "account              0\n",
      "sector               0\n",
      "year_established     0\n",
      "revenue              0\n",
      "employees            0\n",
      "office_location      0\n",
      "dtype: int64\n",
      "Missing Values for DictData\n",
      "Table          0\n",
      "Field          0\n",
      "Description    0\n",
      "dtype: int64\n",
      "Missing Values for Products\n",
      "product        0\n",
      "series         0\n",
      "sales_price    0\n",
      "dtype: int64\n",
      "Missing Values for Pipeline\n",
      "close_date        2089\n",
      "close_value       2089\n",
      "account           1425\n",
      "engage_date        500\n",
      "opportunity_id       0\n",
      "sales_agent          0\n",
      "product              0\n",
      "deal_stage           0\n",
      "dtype: int64\n",
      "Missing Values for Teams\n",
      "sales_agent        0\n",
      "manager            0\n",
      "regional_office    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T21:12:04.310662Z",
     "start_time": "2025-09-12T21:12:04.217204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clean_datasets(datasets)\n",
    "standerizeColumnNames(datasets)\n",
    "standardize_dates(datasets)\n",
    "currency_standard(datasets)"
   ],
   "id": "c85dc911e95cba6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Datasets\n",
      "Dataset Cleaned\n",
      "standerizing columns Accounts\n",
      "Completed: Accounts\n",
      "standerizing columns DictData\n",
      "Completed: DictData\n",
      "standerizing columns Products\n",
      "Completed: Products\n",
      "standerizing columns Pipeline\n",
      "Completed: Pipeline\n",
      "standerizing columns Teams\n",
      "Completed: Teams\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T21:12:04.709581Z",
     "start_time": "2025-09-12T21:12:04.673005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def analysisDataSets(dataDict_List):\n",
    "    for name, df in dataDict_List.items():\n",
    "        print(f\"Information of {name}:\")\n",
    "        df.info()\n",
    "analysisDataSets(datasets)"
   ],
   "id": "378e6cfb70ed2d0d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of Accounts:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85 entries, 0 to 84\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   account           85 non-null     object \n",
      " 1   sector            85 non-null     object \n",
      " 2   year_established  85 non-null     int64  \n",
      " 3   revenue           85 non-null     float64\n",
      " 4   employees         85 non-null     int64  \n",
      " 5   office_location   85 non-null     object \n",
      " 6   subsidiary_of     85 non-null     object \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 4.8+ KB\n",
      "Information of DictData:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21 entries, 0 to 20\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Table        21 non-null     object\n",
      " 1   Field        21 non-null     object\n",
      " 2   Description  21 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 636.0+ bytes\n",
      "Information of Products:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   product      7 non-null      object\n",
      " 1   series       7 non-null      object\n",
      " 2   sales_price  7 non-null      int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 300.0+ bytes\n",
      "Information of Pipeline:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8800 entries, 0 to 8799\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   opportunity_id  8800 non-null   object        \n",
      " 1   sales_agent     8800 non-null   object        \n",
      " 2   product         8800 non-null   object        \n",
      " 3   account         8800 non-null   object        \n",
      " 4   deal_stage      8800 non-null   object        \n",
      " 5   engage_date     8800 non-null   datetime64[ns]\n",
      " 6   close_date      8800 non-null   datetime64[ns]\n",
      " 7   close_value     8800 non-null   float64       \n",
      "dtypes: datetime64[ns](2), float64(1), object(5)\n",
      "memory usage: 550.1+ KB\n",
      "Information of Teams:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35 entries, 0 to 34\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   sales_agent      35 non-null     object\n",
      " 1   manager          35 non-null     object\n",
      " 2   regional_office  35 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 972.0+ bytes\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T21:14:19.424146Z",
     "start_time": "2025-09-12T21:14:19.354485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_csv(dataDict_List):\n",
    "    os.makedirs(\"data_cleaned\", exist_ok=True)\n",
    "    for name, df in dataDict_List.items():\n",
    "        try:\n",
    "           df.to_csv(f\"data_cleaned/{name}.csv\", index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save {name}: {e}\")"
   ],
   "id": "5ed6f131d5ad486d",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-12T21:14:54.607976Z",
     "start_time": "2025-09-12T21:14:54.523167Z"
    }
   },
   "cell_type": "code",
   "source": "save_csv(datasets)",
   "id": "99696171beb9ed04",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "81dabbad0199f6d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
